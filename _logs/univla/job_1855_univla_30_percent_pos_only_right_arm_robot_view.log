=== UNIFIED LOG FOR UNIVLA_30_PERCENT_POS_ONLY_RIGHT_ARM_ROBOT_VIEW ===
Generated at: Sat Jul 12 06:43:15 KST 2025
Job ID: 1855

==================================================
STEP 1: DATA CONVERSION
==================================================
Command: python univla/vla_scripts/convert_lerobot_dataset_for_univla_ablation.py --condition univla_30_percent_pos_only_right_arm_robot_view --input-dir /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq --output-dir ./univla/converted_data
Starting data conversion...

✅ Data conversion for condition: univla_30_percent_pos_only_right_arm_robot_view
📂 Input: /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq
📁 Output: ./univla/converted_data
📊 Condition details:
   - Model: univla
   - Data: 30%
   - State: pos_only
   - Action: right_arm
   - Camera: robot_view
   - Action dim: 21
🔍 Found existing converted data at: univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view
📂 66 episodes already converted
✅ Skipping conversion (data already exists)
🎉 Data conversion completed successfully!
✅ Data conversion completed successfully
Data directory: ./univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view

==================================================
STEP 2: TRAINING
==================================================
Command: python univla/vla_scripts/finetune_rlwrld_ablation.py --condition univla_30_percent_pos_only_right_arm_robot_view --data-root-dir ./univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view --output-dir ./univla/outputs/job_1855_univla_univla_30_percent_pos_only_right_arm_robot_view --max-steps 10000 --batch-size 16 --save-steps 5000
Starting training...

2025-07-12 06:43:38.198899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-12 06:43:38.198962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-12 06:43:38.200969: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-12 06:43:42.583856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
✅ Starting training for condition: univla_30_percent_pos_only_right_arm_robot_view
📂 Data: ./univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view
📁 Output: ./univla/outputs/job_1855_univla_univla_30_percent_pos_only_right_arm_robot_view
🔢 Steps: 10000
📊 Batch size: 16
📈 Learning rate: 0.0001
🚀 Starting UniVLA training for condition: univla_30_percent_pos_only_right_arm_robot_view
📊 Condition config: state_dim=33, action_dim=21, name=univla_30_percent_pos_only_right_arm_robot_view
🔄 Loading model and processor...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.36it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  3.99it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.23it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.08it/s]
Using cache found in /virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
📈 Total Trainable Params: 123,963,900
🔄 Loading Latent Action Model...
07/12 [06:44:10] INFO     | >> using MLP layer as FFN  vision_transformer.py:123
📂 Loading training data...
Calculating normalization stats from 66 episodes...
  0%|          | 0/66 [00:00<?, ?it/s]  5%|▍         | 3/66 [00:00<00:02, 23.30it/s] 11%|█         | 7/66 [00:00<00:01, 29.99it/s] 17%|█▋        | 11/66 [00:00<00:02, 26.84it/s] 21%|██        | 14/66 [00:00<00:01, 27.01it/s] 29%|██▉       | 19/66 [00:00<00:01, 31.68it/s] 35%|███▍      | 23/66 [00:00<00:01, 30.91it/s] 41%|████      | 27/66 [00:00<00:01, 27.29it/s] 47%|████▋     | 31/66 [00:01<00:01, 29.19it/s] 53%|█████▎    | 35/66 [00:01<00:01, 26.54it/s] 58%|█████▊    | 38/66 [00:01<00:01, 24.41it/s] 62%|██████▏   | 41/66 [00:01<00:01, 23.08it/s] 67%|██████▋   | 44/66 [00:01<00:00, 23.02it/s] 71%|███████   | 47/66 [00:01<00:00, 22.71it/s] 76%|███████▌  | 50/66 [00:01<00:00, 22.30it/s] 80%|████████  | 53/66 [00:02<00:00, 22.74it/s] 85%|████████▍ | 56/66 [00:02<00:00, 21.76it/s] 89%|████████▉ | 59/66 [00:02<00:00, 20.56it/s] 94%|█████████▍| 62/66 [00:02<00:00, 21.97it/s] 98%|█████████▊| 65/66 [00:02<00:00, 21.63it/s]100%|██████████| 66/66 [00:02<00:00, 24.32it/s]
Loading episode info from univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view...
  0%|          | 0/66 [00:00<?, ?it/s]100%|██████████| 66/66 [00:00<00:00, 1721.06it/s]
  0%|          | 0/66 [00:00<?, ?it/s]100%|██████████| 66/66 [00:00<00:00, 1381.27it/s]
💾 Saving dataset statistics to univla/outputs/job_1855_univla_univla_30_percent_pos_only_right_arm_robot_view/univla_30_percent_pos_only_right_arm_robot_view/dataset_statistics.json
🎯 Starting training...
  0%|          | 0/10000 [00:00<?, ?it/s]                                         Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 777, in main
    finetune_ablation(
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 594, in finetune_ablation
    for batch_idx, batch in enumerate(dataloader):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/accelerate/data_loader.py", line 454, in __iter__
    current_batch = next(dataloader_iter)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view/episode_000028/image_27.png'

❌ Training failed: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_30_percent_pos_only_right_arm_robot_view/episode_000028/image_27.png'


==================================================
SUMMARY
==================================================
Data preparation: ✅ SUCCESS
Training: ✅ SUCCESS
Overall: ✅ SUCCESS
==================================================
