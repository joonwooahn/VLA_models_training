=== UNIFIED LOG FOR UNIVLA_100_PERCENT_POS_VEL_DUAL_ARM_ROBOT_VIEW ===
Generated at: Sat Jul 12 06:50:46 KST 2025
Job ID: 1864

==================================================
STEP 1: DATA CONVERSION
==================================================
Command: python univla/vla_scripts/convert_lerobot_dataset_for_univla_ablation.py --condition univla_100_percent_pos_vel_dual_arm_robot_view --input-dir /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq --output-dir ./univla/converted_data
Starting data conversion...

âœ… Data conversion for condition: univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ“‚ Input: /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq
ğŸ“ Output: ./univla/converted_data
ğŸ“Š Condition details:
   - Model: univla
   - Data: 100%
   - State: pos_vel
   - Action: dual_arm
   - Camera: robot_view
   - Action dim: 42
ğŸ” Found existing converted data at: univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ“‚ 220 episodes already converted
âœ… Skipping conversion (data already exists)
ğŸ‰ Data conversion completed successfully!
âœ… Data conversion completed successfully
Data directory: ./univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view

==================================================
STEP 2: TRAINING
==================================================
Command: python univla/vla_scripts/finetune_rlwrld_ablation.py --condition univla_100_percent_pos_vel_dual_arm_robot_view --data-root-dir ./univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view --output-dir ./univla/outputs/job_1864_univla_univla_100_percent_pos_vel_dual_arm_robot_view --max-steps 10000 --batch-size 16 --save-steps 5000
Starting training...

2025-07-12 06:50:58.755415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-12 06:50:58.755491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-12 06:50:58.756599: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-12 06:51:00.350612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
âœ… Starting training for condition: univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ“‚ Data: ./univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ“ Output: ./univla/outputs/job_1864_univla_univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ”¢ Steps: 10000
ğŸ“Š Batch size: 16
ğŸ“ˆ Learning rate: 0.0001
ğŸš€ Starting UniVLA training for condition: univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ“Š Condition config: state_dim=120, action_dim=42, name=univla_100_percent_pos_vel_dual_arm_robot_view
ğŸ”„ Loading model and processor...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:00,  3.22it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]
Using cache found in /virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
ğŸ“ˆ Total Trainable Params: 124,266,744
ğŸ”„ Loading Latent Action Model...
07/12 [06:51:25] INFO     | >> using MLP layer as FFN  vision_transformer.py:123
ğŸ“‚ Loading training data...
Calculating normalization stats from 220 episodes...
  0%|          | 0/220 [00:00<?, ?it/s]  1%|          | 2/220 [00:00<00:11, 18.26it/s]  2%|â–         | 4/220 [00:00<00:12, 17.50it/s]  3%|â–         | 6/220 [00:00<00:11, 18.05it/s]  4%|â–         | 8/220 [00:00<00:11, 18.11it/s]  5%|â–Œ         | 11/220 [00:00<00:11, 18.18it/s]  6%|â–Œ         | 13/220 [00:00<00:11, 18.61it/s]  7%|â–‹         | 15/220 [00:00<00:12, 16.05it/s]  8%|â–Š         | 17/220 [00:00<00:12, 16.52it/s]  9%|â–Š         | 19/220 [00:01<00:12, 15.95it/s] 10%|â–ˆ         | 22/220 [00:01<00:10, 18.28it/s] 11%|â–ˆ         | 24/220 [00:01<00:10, 18.28it/s] 12%|â–ˆâ–        | 26/220 [00:01<00:11, 17.51it/s] 13%|â–ˆâ–        | 28/220 [00:01<00:14, 13.48it/s] 14%|â–ˆâ–        | 31/220 [00:01<00:11, 16.28it/s] 15%|â–ˆâ–Œ        | 34/220 [00:01<00:10, 17.93it/s] 16%|â–ˆâ–‹        | 36/220 [00:02<00:10, 18.18it/s] 18%|â–ˆâ–Š        | 39/220 [00:02<00:09, 19.15it/s] 19%|â–ˆâ–‰        | 42/220 [00:02<00:08, 20.58it/s] 20%|â–ˆâ–ˆ        | 45/220 [00:02<00:09, 18.94it/s] 21%|â–ˆâ–ˆâ–       | 47/220 [00:02<00:10, 16.54it/s] 22%|â–ˆâ–ˆâ–       | 49/220 [00:02<00:10, 16.73it/s] 23%|â–ˆâ–ˆâ–       | 51/220 [00:02<00:09, 17.44it/s] 24%|â–ˆâ–ˆâ–       | 53/220 [00:03<00:09, 16.89it/s] 25%|â–ˆâ–ˆâ–Œ       | 55/220 [00:03<00:09, 17.58it/s] 26%|â–ˆâ–ˆâ–Œ       | 57/220 [00:03<00:09, 17.30it/s] 27%|â–ˆâ–ˆâ–‹       | 59/220 [00:03<00:09, 17.15it/s] 28%|â–ˆâ–ˆâ–Š       | 61/220 [00:03<00:08, 17.73it/s] 29%|â–ˆâ–ˆâ–‰       | 64/220 [00:03<00:08, 18.62it/s] 30%|â–ˆâ–ˆâ–ˆ       | 67/220 [00:03<00:08, 17.44it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 70/220 [00:03<00:07, 19.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 73/220 [00:04<00:07, 18.96it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 75/220 [00:04<00:08, 17.70it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 78/220 [00:04<00:07, 19.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 81/220 [00:04<00:06, 20.78it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 84/220 [00:04<00:06, 20.75it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 87/220 [00:04<00:06, 21.28it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 90/220 [00:04<00:05, 22.59it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/220 [00:05<00:05, 22.82it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 96/220 [00:05<00:05, 22.59it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 99/220 [00:05<00:05, 22.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 102/220 [00:05<00:05, 23.38it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 105/220 [00:05<00:04, 23.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 108/220 [00:05<00:05, 21.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 111/220 [00:05<00:04, 22.62it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/220 [00:05<00:04, 23.35it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 117/220 [00:06<00:04, 21.43it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/220 [00:06<00:05, 19.16it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 123/220 [00:06<00:04, 19.82it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 126/220 [00:06<00:04, 21.79it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 129/220 [00:06<00:04, 21.92it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 132/220 [00:06<00:04, 20.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 135/220 [00:06<00:03, 21.83it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 138/220 [00:07<00:03, 21.44it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 141/220 [00:07<00:03, 23.14it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 144/220 [00:07<00:03, 23.65it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 147/220 [00:07<00:03, 23.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 150/220 [00:07<00:02, 25.11it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 153/220 [00:07<00:02, 25.46it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 156/220 [00:07<00:02, 25.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 160/220 [00:07<00:02, 27.28it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 163/220 [00:08<00:02, 25.82it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 166/220 [00:08<00:02, 25.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 169/220 [00:08<00:02, 23.34it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 172/220 [00:08<00:02, 20.11it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 175/220 [00:08<00:02, 19.54it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 178/220 [00:08<00:02, 19.32it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 181/220 [00:08<00:01, 21.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 184/220 [00:09<00:01, 21.48it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 187/220 [00:09<00:01, 22.55it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 190/220 [00:09<00:01, 21.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 193/220 [00:09<00:01, 19.25it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 195/220 [00:09<00:01, 18.86it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 197/220 [00:09<00:01, 18.28it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 199/220 [00:09<00:01, 16.79it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 202/220 [00:10<00:01, 17.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 204/220 [00:10<00:00, 17.78it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 207/220 [00:10<00:00, 19.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 210/220 [00:10<00:00, 19.28it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 212/220 [00:10<00:00, 19.22it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 214/220 [00:10<00:00, 15.45it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 216/220 [00:10<00:00, 16.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 219/220 [00:11<00:00, 16.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [00:11<00:00, 19.75it/s]
âš ï¸  Warning: Action dimensions [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41] have zero or very small std. Setting to 1e-8 to prevent NaN.
Loading episode info from univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view...
  0%|          | 0/220 [00:00<?, ?it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 179/220 [00:00<00:00, 1780.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [00:00<00:00, 1768.71it/s]
  0%|          | 0/220 [00:00<?, ?it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 171/220 [00:00<00:00, 1705.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [00:00<00:00, 1725.53it/s]
ğŸ’¾ Saving dataset statistics to univla/outputs/job_1864_univla_univla_100_percent_pos_vel_dual_arm_robot_view/univla_100_percent_pos_vel_dual_arm_robot_view/dataset_statistics.json
ğŸ¯ Starting training...
  0%|          | 0/10000 [00:00<?, ?it/s]                                         Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 777, in main
    finetune_ablation(
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 594, in finetune_ablation
    for batch_idx, batch in enumerate(dataloader):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/accelerate/data_loader.py", line 454, in __iter__
    current_batch = next(dataloader_iter)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view/episode_000046/image_19.png'

âŒ Training failed: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_100_percent_pos_vel_dual_arm_robot_view/episode_000046/image_19.png'


==================================================
SUMMARY
==================================================
Data preparation: âœ… SUCCESS
Training: âœ… SUCCESS
Overall: âœ… SUCCESS
==================================================
