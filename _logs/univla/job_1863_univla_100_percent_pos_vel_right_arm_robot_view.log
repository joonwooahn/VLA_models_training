=== UNIFIED LOG FOR UNIVLA_100_PERCENT_POS_VEL_RIGHT_ARM_ROBOT_VIEW ===
Generated at: Sat Jul 12 06:49:45 KST 2025
Job ID: 1863

==================================================
STEP 1: DATA CONVERSION
==================================================
Command: python univla/vla_scripts/convert_lerobot_dataset_for_univla_ablation.py --condition univla_100_percent_pos_vel_right_arm_robot_view --input-dir /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq --output-dir ./univla/converted_data
Starting data conversion...

‚úÖ Data conversion for condition: univla_100_percent_pos_vel_right_arm_robot_view
üìÇ Input: /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq
üìÅ Output: ./univla/converted_data
üìä Condition details:
   - Model: univla
   - Data: 100%
   - State: pos_vel
   - Action: right_arm
   - Camera: robot_view
   - Action dim: 21
üîç Found existing converted data at: univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view
üìÇ 220 episodes already converted
‚úÖ Skipping conversion (data already exists)
üéâ Data conversion completed successfully!
‚úÖ Data conversion completed successfully
Data directory: ./univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view

==================================================
STEP 2: TRAINING
==================================================
Command: python univla/vla_scripts/finetune_rlwrld_ablation.py --condition univla_100_percent_pos_vel_right_arm_robot_view --data-root-dir ./univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view --output-dir ./univla/outputs/job_1863_univla_univla_100_percent_pos_vel_right_arm_robot_view --max-steps 10000 --batch-size 16 --save-steps 5000
Starting training...

2025-07-12 06:49:54.333347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-12 06:49:54.333418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-12 06:49:54.335527: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-12 06:49:55.980568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
‚úÖ Starting training for condition: univla_100_percent_pos_vel_right_arm_robot_view
üìÇ Data: ./univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view
üìÅ Output: ./univla/outputs/job_1863_univla_univla_100_percent_pos_vel_right_arm_robot_view
üî¢ Steps: 10000
üìä Batch size: 16
üìà Learning rate: 0.0001
üöÄ Starting UniVLA training for condition: univla_100_percent_pos_vel_right_arm_robot_view
üìä Condition config: state_dim=66, action_dim=21, name=univla_100_percent_pos_vel_right_arm_robot_view
üîÑ Loading model and processor...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  3.36it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  4.00it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.97it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.90it/s]
Using cache found in /virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/virtual_lab/rlwrld/david/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
üìà Total Trainable Params: 123,980,796
üîÑ Loading Latent Action Model...
07/12 [06:50:19] INFO     | >> using MLP layer as FFN  vision_transformer.py:123
üìÇ Loading training data...
Calculating normalization stats from 220 episodes...
  0%|          | 0/220 [00:00<?, ?it/s]  1%|‚ñè         | 3/220 [00:00<00:09, 21.81it/s]  3%|‚ñé         | 6/220 [00:00<00:09, 23.14it/s]  4%|‚ñç         | 9/220 [00:00<00:08, 24.88it/s]  6%|‚ñå         | 13/220 [00:00<00:07, 26.87it/s]  7%|‚ñã         | 16/220 [00:00<00:07, 26.60it/s]  9%|‚ñä         | 19/220 [00:00<00:07, 25.36it/s] 10%|‚ñà         | 22/220 [00:00<00:08, 23.46it/s] 11%|‚ñà‚ñè        | 25/220 [00:01<00:07, 24.65it/s] 13%|‚ñà‚ñé        | 28/220 [00:01<00:08, 21.52it/s] 14%|‚ñà‚ñç        | 31/220 [00:01<00:08, 21.98it/s] 15%|‚ñà‚ñå        | 34/220 [00:01<00:07, 23.37it/s] 17%|‚ñà‚ñã        | 37/220 [00:01<00:07, 24.39it/s] 18%|‚ñà‚ñä        | 40/220 [00:01<00:07, 24.75it/s] 20%|‚ñà‚ñà        | 44/220 [00:01<00:06, 28.53it/s] 21%|‚ñà‚ñà‚ñè       | 47/220 [00:01<00:06, 28.57it/s] 23%|‚ñà‚ñà‚ñé       | 50/220 [00:02<00:06, 25.56it/s] 24%|‚ñà‚ñà‚ñç       | 53/220 [00:02<00:06, 25.88it/s] 25%|‚ñà‚ñà‚ñå       | 56/220 [00:02<00:06, 25.20it/s] 27%|‚ñà‚ñà‚ñã       | 59/220 [00:02<00:07, 22.80it/s] 28%|‚ñà‚ñà‚ñä       | 62/220 [00:02<00:06, 23.17it/s] 30%|‚ñà‚ñà‚ñâ       | 65/220 [00:02<00:06, 22.54it/s] 31%|‚ñà‚ñà‚ñà       | 68/220 [00:02<00:07, 20.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/220 [00:03<00:07, 19.61it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 74/220 [00:03<00:07, 18.44it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 77/220 [00:03<00:07, 19.56it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 80/220 [00:03<00:07, 19.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 83/220 [00:03<00:07, 18.80it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 85/220 [00:03<00:07, 18.22it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 87/220 [00:03<00:07, 18.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 90/220 [00:04<00:06, 19.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 92/220 [00:04<00:06, 18.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 95/220 [00:04<00:06, 20.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 98/220 [00:04<00:06, 18.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 101/220 [00:04<00:06, 19.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 104/220 [00:04<00:05, 21.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/220 [00:04<00:05, 19.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 110/220 [00:05<00:05, 19.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 113/220 [00:05<00:05, 21.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 116/220 [00:05<00:05, 19.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 119/220 [00:05<00:05, 18.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 121/220 [00:05<00:05, 18.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 123/220 [00:05<00:05, 18.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 125/220 [00:05<00:05, 17.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 127/220 [00:05<00:05, 17.95it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 130/220 [00:06<00:04, 20.13it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 133/220 [00:06<00:03, 21.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 136/220 [00:06<00:03, 21.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 139/220 [00:06<00:03, 20.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 142/220 [00:06<00:03, 21.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 145/220 [00:06<00:03, 21.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 148/220 [00:06<00:03, 20.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 151/220 [00:07<00:03, 21.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 154/220 [00:07<00:03, 19.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 156/220 [00:07<00:03, 18.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 158/220 [00:07<00:03, 18.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 160/220 [00:07<00:03, 18.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 162/220 [00:07<00:03, 18.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 164/220 [00:07<00:03, 18.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 166/220 [00:08<00:03, 14.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 168/220 [00:08<00:03, 15.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 170/220 [00:08<00:03, 15.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 173/220 [00:08<00:02, 17.85it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 176/220 [00:08<00:02, 19.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 179/220 [00:08<00:01, 21.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 182/220 [00:08<00:01, 20.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 185/220 [00:08<00:01, 19.20it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 189/220 [00:09<00:01, 21.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 192/220 [00:09<00:01, 21.09it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 195/220 [00:09<00:01, 19.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 198/220 [00:09<00:01, 19.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 201/220 [00:09<00:00, 20.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 204/220 [00:09<00:00, 21.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 207/220 [00:09<00:00, 20.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 210/220 [00:10<00:00, 20.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 213/220 [00:10<00:00, 21.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 216/220 [00:10<00:00, 19.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 219/220 [00:10<00:00, 19.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220/220 [00:10<00:00, 20.64it/s]
Loading episode info from univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view...
  0%|          | 0/220 [00:00<?, ?it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 169/220 [00:00<00:00, 1680.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220/220 [00:00<00:00, 1631.76it/s]
  0%|          | 0/220 [00:00<?, ?it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 142/220 [00:00<00:00, 1413.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220/220 [00:00<00:00, 1487.08it/s]
üíæ Saving dataset statistics to univla/outputs/job_1863_univla_univla_100_percent_pos_vel_right_arm_robot_view/univla_100_percent_pos_vel_right_arm_robot_view/dataset_statistics.json
üéØ Starting training...
  0%|          | 0/10000 [00:00<?, ?it/s]                                         Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 777, in main
    finetune_ablation(
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 594, in finetune_ablation
    for batch_idx, batch in enumerate(dataloader):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/accelerate/data_loader.py", line 454, in __iter__
    current_batch = next(dataloader_iter)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view/episode_000047/image_33.png'

‚ùå Training failed: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/virtual_lab/rlwrld/david/VLA_models_training/univla/vla_scripts/finetune_rlwrld_ablation.py", line 167, in __getitem__
    pixel_values = self.image_transform(Image.open(main_image_path).convert("RGB"))
  File "/virtual_lab/rlwrld/david/miniconda3/envs/univla_train/lib/python3.10/site-packages/PIL/Image.py", line 3505, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'univla/converted_data/univla_100_percent_pos_vel_right_arm_robot_view/episode_000047/image_33.png'


==================================================
SUMMARY
==================================================
Data preparation: ‚úÖ SUCCESS
Training: ‚úÖ SUCCESS
Overall: ‚úÖ SUCCESS
==================================================
