=== UNIFIED LOG FOR PI0_FAST_30_PERCENT_POS_ONLY_RIGHT_ARM_ROBOT_VIEW ===
Generated at: Mon Jul 14 19:35:50 KST 2025
Job ID: 2853

==================================================
ENVIRONMENT CHECK
==================================================
Available conda environments:

# conda environments:
#
base                 * /virtual_lab/rlwrld/david/miniconda3
conversion_env         /virtual_lab/rlwrld/david/miniconda3/envs/conversion_env
gr00t                  /virtual_lab/rlwrld/david/miniconda3/envs/gr00t
lerobot                /virtual_lab/rlwrld/david/miniconda3/envs/lerobot
openpi_env             /virtual_lab/rlwrld/david/miniconda3/envs/openpi_env
univla_train           /virtual_lab/rlwrld/david/miniconda3/envs/univla_train


Activating lerobot environment...

Current Python path:
/virtual_lab/rlwrld/david/miniconda3/envs/lerobot/bin/python

Python version:
Python 3.13.5

Checking transformers installation...
transformers version: 4.51.3
==================================================

==================================================
STEP 1: DATA CONVERSION
==================================================
Command: cd pi0 && python convert_dataset_for_ablation.py --condition pi0_fast_30_percent_pos_only_right_arm_robot_view --input-dir /virtual_lab/rlwrld/david/.cache/huggingface/lerobot/RLWRLD/allex_gesture_easy_pos_vel_torq --output-dir ../converted_datasets_ablation
Starting data conversion...

üîß PI0/PI0_FAST Dataset Conversion Tool
============================================================
üí° Note: GR00T and UniVLA already have proper joint filtering
üí° This tool is primarily for PI0/PI0_FAST which use simple dimension cutting

üéØ Converting single condition: pi0_fast_30_percent_pos_only_right_arm_robot_view
üîç Found existing converted data at: ../converted_datasets_ablation/pi0_fast_30_percent_pos_only_right_arm_robot_view
üìÇ 66 episodes already converted
‚úÖ Skipping conversion (data already exists)
üéâ Single condition conversion completed!
üìÅ Dataset available at: ../converted_datasets_ablation/pi0_fast_30_percent_pos_only_right_arm_robot_view
‚úÖ Data conversion completed successfully
Data directory: ./converted_datasets_ablation/pi0_fast_30_percent_pos_only_right_arm_robot_view

==================================================
STEP 2: TRAINING
==================================================
PYTHONPATH: /virtual_lab/rlwrld/david/VLA_models_training/pi0:$PYTHONPATH
Command: python pi0/lerobot/scripts/train.py --dataset.path=./converted_datasets_ablation/pi0_fast_30_percent_pos_only_right_arm_robot_view --policy.path=lerobot/pi0fast_base --output_dir=./pi0/outputs/job_2853_pi0_fast_pi0_fast_30_percent_pos_only_right_arm_robot_view --steps=5000 --batch_size=16 --seed=1000 --save_freq=1000 --num_workers=8
Starting training...

usage: train.py [-h] [--config_path str] [--dataset str]
                [--dataset.repo_id str] [--dataset.root str]
                [--dataset.episodes str] [--image_transforms str]
                [--dataset.image_transforms.enable str]
                [--dataset.image_transforms.max_num_transforms str]
                [--dataset.image_transforms.random_order str]
                [--dataset.image_transforms.tfs str] [--dataset.revision str]
                [--dataset.use_imagenet_stats str]
                [--dataset.video_backend str] [--env str] [--env.obs_type str]
                [--env.render_mode str] [--env.visualization_width str]
                [--env.visualization_height str] [--robot str]
                [--env.robot.type str] [--teleop str] [--env.teleop.type str]
                [--env.task str] [--env.fps str] [--env.features str]
                [--env.features_map str] [--env.type str] [--env.name str]
                [--env.use_viewer str] [--env.gripper_penalty str]
                [--env.use_gamepad str] [--env.state_dim str]
                [--env.action_dim str] [--env.episode_length str]
                [--video_record str] [--env.video_record.enabled str]
                [--env.video_record.record_dir str]
                [--env.video_record.trajectory_name str]
                [--env.reward_classifier_pretrained_path str]
                [--robot_config str] [--env.robot_config.type str]
                [--teleop_config str] [--env.teleop_config.type str]
                [--wrapper str] [--env.wrapper.control_mode str]
                [--env.wrapper.display_cameras str]
                [--env.wrapper.add_joint_velocity_to_observation str]
                [--env.wrapper.add_current_to_observation str]
                [--env.wrapper.add_ee_pose_to_observation str]
                [--env.wrapper.crop_params_dict str]
                [--env.wrapper.resize_size str]
                [--env.wrapper.control_time_s str]
                [--env.wrapper.fixed_reset_joint_positions str]
                [--env.wrapper.reset_time_s str]
                [--env.wrapper.use_gripper str]
                [--env.wrapper.gripper_quantization_threshold str]
                [--env.wrapper.gripper_penalty str]
                [--env.wrapper.gripper_penalty_in_reward str] [--env.mode str]
                [--env.repo_id str] [--env.dataset_root str]
                [--env.num_episodes str] [--env.episode str]
                [--env.device str] [--env.push_to_hub str]
                [--env.pretrained_policy_name_or_path str]
                [--env.number_of_steps_after_success str] [--policy str]
                [--policy.type {act,diffusion,pi0,smolvla,tdmpc,vqbet,pi0fast,sac,reward_classifier}]
                [--policy.replace_final_stride_with_dilation str]
                [--policy.pre_norm str] [--policy.dim_model str]
                [--policy.n_heads str] [--policy.dim_feedforward str]
                [--policy.feedforward_activation str]
                [--policy.n_encoder_layers str]
                [--policy.n_decoder_layers str] [--policy.use_vae str]
                [--policy.n_vae_encoder_layers str]
                [--policy.temporal_ensemble_coeff str]
                [--policy.kl_weight str] [--policy.optimizer_lr_backbone str]
                [--policy.drop_n_last_frames str]
                [--policy.use_separate_rgb_encoder_per_camera str]
                [--policy.down_dims str] [--policy.kernel_size str]
                [--policy.n_groups str]
                [--policy.diffusion_step_embed_dim str]
                [--policy.use_film_scale_modulation str]
                [--policy.noise_scheduler_type str]
                [--policy.num_train_timesteps str]
                [--policy.beta_schedule str] [--policy.beta_start str]
                [--policy.beta_end str] [--policy.prediction_type str]
                [--policy.clip_sample str] [--policy.clip_sample_range str]
                [--policy.num_inference_steps str]
                [--policy.do_mask_loss_for_padding str]
                [--policy.scheduler_name str]
                [--policy.attention_implementation str]
                [--policy.num_steps str] [--policy.train_expert_only str]
                [--policy.train_state_proj str]
                [--policy.optimizer_grad_clip_norm str]
                [--policy.vlm_model_name str] [--policy.load_vlm_weights str]
                [--policy.add_image_special_tokens str]
                [--policy.attention_mode str] [--policy.prefix_length str]
                [--policy.pad_language_to str]
                [--policy.num_expert_layers str] [--policy.num_vlm_layers str]
                [--policy.self_attn_every_n_layers str]
                [--policy.expert_width_multiplier str]
                [--policy.min_period str] [--policy.max_period str]
                [--policy.n_action_repeats str] [--policy.horizon str]
                [--policy.q_ensemble_size str] [--policy.mlp_dim str]
                [--policy.use_mpc str] [--policy.cem_iterations str]
                [--policy.max_std str] [--policy.min_std str]
                [--policy.n_gaussian_samples str] [--policy.n_pi_samples str]
                [--policy.uncertainty_regularizer_coeff str]
                [--policy.n_elites str]
                [--policy.elite_weighting_temperature str]
                [--policy.gaussian_mean_momentum str]
                [--policy.max_random_shift_ratio str]
                [--policy.reward_coeff str] [--policy.expectile_weight str]
                [--policy.value_coeff str] [--policy.consistency_coeff str]
                [--policy.advantage_scaling str] [--policy.pi_coeff str]
                [--policy.temporal_decay_coeff str]
                [--policy.target_model_momentum str]
                [--policy.n_action_pred_token str]
                [--policy.action_chunk_size str]
                [--policy.vision_backbone str] [--policy.crop_shape str]
                [--policy.crop_is_random str]
                [--policy.pretrained_backbone_weights str]
                [--policy.use_group_norm str]
                [--policy.spatial_softmax_num_keypoints str]
                [--policy.n_vqvae_training_steps str]
                [--policy.vqvae_n_embed str]
                [--policy.vqvae_embedding_dim str]
                [--policy.vqvae_enc_hidden_dim str]
                [--policy.gpt_block_size str] [--policy.gpt_input_dim str]
                [--policy.gpt_output_dim str] [--policy.gpt_n_layer str]
                [--policy.gpt_n_head str] [--policy.gpt_hidden_dim str]
                [--policy.dropout str] [--policy.mlp_hidden_dim str]
                [--policy.offset_loss_weight str]
                [--policy.primary_code_loss_weight str]
                [--policy.secondary_code_loss_weight str]
                [--policy.bet_softmax_temperature str]
                [--policy.sequentially_select str]
                [--policy.optimizer_vqvae_lr str]
                [--policy.optimizer_vqvae_weight_decay str]
                [--policy.chunk_size str] [--policy.n_action_steps str]
                [--policy.max_state_dim str] [--policy.max_action_dim str]
                [--policy.use_extended_dim str] [--policy.ext_state_dim str]
                [--policy.ext_action_dim str] [--policy.state_indices str]
                [--policy.action_indices str]
                [--policy.resize_imgs_with_padding str]
                [--policy.interpolate_like_pi str]
                [--policy.empty_cameras str] [--policy.adapt_to_pi_aloha str]
                [--policy.use_delta_joint_actions_aloha str]
                [--policy.tokenizer_max_length str] [--policy.proj_width str]
                [--policy.max_decoding_steps str]
                [--policy.fast_skip_tokens str]
                [--policy.max_input_seq_len str] [--policy.use_cache str]
                [--policy.freeze_lm_head str] [--policy.optimizer_lr str]
                [--policy.optimizer_betas str] [--policy.optimizer_eps str]
                [--policy.optimizer_weight_decay str]
                [--policy.scheduler_warmup_steps str]
                [--policy.scheduler_decay_steps str]
                [--policy.scheduler_decay_lr str]
                [--policy.checkpoint_path str] [--policy.padding_side str]
                [--policy.precision str]
                [--policy.relaxed_action_decoding str]
                [--policy.dataset_stats str] [--policy.storage_device str]
                [--policy.vision_encoder_name str]
                [--policy.freeze_vision_encoder str]
                [--policy.image_encoder_hidden_dim str]
                [--policy.shared_encoder str]
                [--policy.num_discrete_actions str]
                [--policy.online_steps str] [--policy.online_env_seed str]
                [--policy.online_buffer_capacity str]
                [--policy.offline_buffer_capacity str]
                [--policy.async_prefetch str]
                [--policy.online_step_before_learning str]
                [--policy.policy_update_freq str] [--policy.discount str]
                [--policy.temperature_init str] [--policy.num_critics str]
                [--policy.num_subsample_critics str] [--policy.critic_lr str]
                [--policy.actor_lr str] [--policy.temperature_lr str]
                [--policy.critic_target_update_weight str]
                [--policy.utd_ratio str]
                [--policy.state_encoder_hidden_dim str]
                [--policy.target_entropy str]
                [--policy.use_backup_entropy str]
                [--critic_network_kwargs str]
                [--policy.critic_network_kwargs.hidden_dims str]
                [--policy.critic_network_kwargs.activate_final str]
                [--policy.critic_network_kwargs.final_activation str]
                [--actor_network_kwargs str]
                [--policy.actor_network_kwargs.hidden_dims str]
                [--policy.actor_network_kwargs.activate_final str]
                [--policy_kwargs str]
                [--policy.policy_kwargs.use_tanh_squash str]
                [--policy.policy_kwargs.std_min str]
                [--policy.policy_kwargs.std_max str]
                [--policy.policy_kwargs.init_final str]
                [--discrete_critic_network_kwargs str]
                [--policy.discrete_critic_network_kwargs.hidden_dims str]
                [--policy.discrete_critic_network_kwargs.activate_final str]
                [--policy.discrete_critic_network_kwargs.final_activation str]
                [--actor_learner_config str]
                [--policy.actor_learner_config.learner_host str]
                [--policy.actor_learner_config.learner_port str]
                [--policy.actor_learner_config.policy_parameters_push_frequency str]
                [--policy.actor_learner_config.queue_get_timeout str]
                [--concurrency str] [--policy.concurrency.actor str]
                [--policy.concurrency.learner str]
                [--policy.use_torch_compile str] [--policy.n_obs_steps str]
                [--policy.normalization_mapping str]
                [--policy.input_features str] [--policy.output_features str]
                [--policy.device str] [--policy.use_amp str]
                [--policy.name str] [--policy.num_classes str]
                [--policy.hidden_dim str] [--policy.latent_dim str]
                [--policy.image_embedding_pooling_dim str]
                [--policy.dropout_rate str] [--policy.model_name str]
                [--policy.model_type str] [--policy.num_cameras str]
                [--policy.learning_rate str] [--policy.weight_decay str]
                [--policy.grad_clip_norm str] [--output_dir str]
                [--job_name str] [--resume str] [--seed str]
                [--num_workers str] [--batch_size str] [--steps str]
                [--eval_freq str] [--log_freq str] [--save_checkpoint str]
                [--save_freq str] [--use_policy_training_preset str]
                [--optimizer str]
                [--optimizer.type {adam,adamw,sgd,multi_adam}]
                [--optimizer.betas str] [--optimizer.eps str]
                [--optimizer.momentum str] [--optimizer.dampening str]
                [--optimizer.nesterov str] [--optimizer.lr str]
                [--optimizer.weight_decay str]
                [--optimizer.grad_clip_norm str]
                [--optimizer.optimizer_groups str] [--scheduler str]
                [--scheduler.type {diffuser,vqbet,cosine_decay_with_warmup}]
                [--scheduler.name str]
                [--scheduler.num_vqvae_training_steps str]
                [--scheduler.num_cycles str]
                [--scheduler.num_warmup_steps str]
                [--scheduler.num_decay_steps str] [--scheduler.peak_lr str]
                [--scheduler.decay_lr str] [--eval str]
                [--eval.n_episodes str] [--eval.batch_size str]
                [--eval.use_async_envs str] [--wandb str] [--wandb.enable str]
                [--wandb.disable_artifact str] [--wandb.project str]
                [--wandb.entity str] [--wandb.notes str] [--wandb.run_id str]
                [--wandb.mode str]
train.py: error: unrecognized arguments: --dataset.path=./converted_datasets_ablation/pi0_fast_30_percent_pos_only_right_arm_robot_view

==================================================
SUMMARY
==================================================
Data preparation: ‚úÖ SUCCESS
Training: ‚ùå FAILED
Overall: ‚ùå FAILED
==================================================
